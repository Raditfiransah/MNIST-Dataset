{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4a468e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-31 10:53:07.403400: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-10-31 10:53:07.544881: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1761882787.561018    5533 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1761882787.570564    5533 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-31 10:53:07.650833: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datasets import load_dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a1bc800d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_dataset(\"ylecun/mnist\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "abe6c0cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(example_batch):\n",
    "    images = [np.array(img) for img in example_batch[\"image\"]]\n",
    "    images = np.expand_dims(images, -1) / 255.0\n",
    "    labels = np.array(example_batch[\"label\"])\n",
    "    return {\"pixel_values\": images, \"labels\": labels}\n",
    "\n",
    "ds = ds.map(preprocess, batched=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "17634ba2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1761882874.444434    5533 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6141 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 4060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.9\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Column.__init__() missing 1 required positional argument: 'column_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[57]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m train_set = \u001b[43mtf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDataset\u001b[49m\u001b[43m.\u001b[49m\u001b[43mfrom_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43m(\u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpixel_values\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mds\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtrain\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlabels\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m)\u001b[49m.batch(\u001b[32m32\u001b[39m)\n\u001b[32m      5\u001b[39m test_set = tf.data.Dataset.from_tensor_slices(\n\u001b[32m      6\u001b[39m     (ds[\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mpixel_values\u001b[39m\u001b[33m\"\u001b[39m], ds[\u001b[33m\"\u001b[39m\u001b[33mtest\u001b[39m\u001b[33m\"\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mlabels\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      7\u001b[39m ).batch(\u001b[32m32\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/data/ops/dataset_ops.py:827\u001b[39m, in \u001b[36mDatasetV2.from_tensor_slices\u001b[39m\u001b[34m(tensors, name)\u001b[39m\n\u001b[32m    823\u001b[39m \u001b[38;5;66;03m# Loaded lazily due to a circular dependency (dataset_ops ->\u001b[39;00m\n\u001b[32m    824\u001b[39m \u001b[38;5;66;03m# from_tensor_slices_op -> dataset_ops).\u001b[39;00m\n\u001b[32m    825\u001b[39m \u001b[38;5;66;03m# pylint: disable=g-import-not-at-top,protected-access\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtensorflow\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpython\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mops\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m from_tensor_slices_op\n\u001b[32m--> \u001b[39m\u001b[32m827\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfrom_tensor_slices_op\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_from_tensor_slices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:25\u001b[39m, in \u001b[36m_from_tensor_slices\u001b[39m\u001b[34m(tensors, name)\u001b[39m\n\u001b[32m     24\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_from_tensor_slices\u001b[39m(tensors, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m---> \u001b[39m\u001b[32m25\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_TensorSliceDataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/data/ops/from_tensor_slices_op.py:33\u001b[39m, in \u001b[36m_TensorSliceDataset.__init__\u001b[39m\u001b[34m(self, element, is_files, name)\u001b[39m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, element, is_files=\u001b[38;5;28;01mFalse\u001b[39;00m, name=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m     32\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"See `Dataset.from_tensor_slices` for details.\"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m   element = \u001b[43mstructure\u001b[49m\u001b[43m.\u001b[49m\u001b[43mnormalize_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m   batched_spec = structure.type_spec_from_value(element)\n\u001b[32m     35\u001b[39m   \u001b[38;5;28mself\u001b[39m._tensors = structure.to_batched_tensor_list(batched_spec, element)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/data/util/structure.py:135\u001b[39m, in \u001b[36mnormalize_element\u001b[39m\u001b[34m(element, element_signature)\u001b[39m\n\u001b[32m    132\u001b[39m         dtype = \u001b[38;5;28mgetattr\u001b[39m(spec, \u001b[33m\"\u001b[39m\u001b[33mdtype\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    133\u001b[39m         normalized_components.append(\n\u001b[32m    134\u001b[39m             ops.convert_to_tensor(t, name=\u001b[33m\"\u001b[39m\u001b[33mcomponent_\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m\"\u001b[39m % i, dtype=dtype))\n\u001b[32m--> \u001b[39m\u001b[32m135\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpack_as\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnormalized_components\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/data/util/nest.py:87\u001b[39m, in \u001b[36mpack_sequence_as\u001b[39m\u001b[34m(structure, flat_sequence)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mpack_sequence_as\u001b[39m(structure, flat_sequence):\n\u001b[32m     70\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"Returns a given flattened sequence packed into a nest.\u001b[39;00m\n\u001b[32m     71\u001b[39m \n\u001b[32m     72\u001b[39m \u001b[33;03m  If `structure` is a scalar, `flat_sequence` must be a single-element list;\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     85\u001b[39m \u001b[33;03m    ValueError: If nest and structure have different element counts.\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m87\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mnest_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m      \u001b[49m\u001b[43mnest_util\u001b[49m\u001b[43m.\u001b[49m\u001b[43mModality\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDATA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexpand_composites\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[32m     89\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:859\u001b[39m, in \u001b[36mpack_sequence_as\u001b[39m\u001b[34m(modality, structure, flat_sequence, expand_composites, sequence_fn)\u001b[39m\n\u001b[32m    855\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m _tf_core_pack_sequence_as(\n\u001b[32m    856\u001b[39m       structure, flat_sequence, expand_composites, sequence_fn\n\u001b[32m    857\u001b[39m   )\n\u001b[32m    858\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m modality == Modality.DATA:\n\u001b[32m--> \u001b[39m\u001b[32m859\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tf_data_pack_sequence_as\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_sequence\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    861\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    862\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mUnknown modality used \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[33m for nested structure\u001b[39m\u001b[33m\"\u001b[39m.format(modality)\n\u001b[32m    863\u001b[39m   )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:963\u001b[39m, in \u001b[36m_tf_data_pack_sequence_as\u001b[39m\u001b[34m(structure, flat_sequence)\u001b[39m\n\u001b[32m    955\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(flat_structure) != \u001b[38;5;28mlen\u001b[39m(flat_sequence):\n\u001b[32m    956\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    957\u001b[39m       \u001b[33m\"\u001b[39m\u001b[33mCould not pack sequence. Argument `structure` had \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    958\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(flat_structure)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m elements, but argument `flat_sequence` had \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    959\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(flat_sequence)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m elements. Received structure: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    960\u001b[39m       \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstructure\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, flat_sequence: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mflat_sequence\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    961\u001b[39m   )\n\u001b[32m--> \u001b[39m\u001b[32m963\u001b[39m _, packed = \u001b[43m_tf_data_packed_nest_with_indices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflat_sequence\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    964\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m sequence_like(structure, packed)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:607\u001b[39m, in \u001b[36m_tf_data_packed_nest_with_indices\u001b[39m\u001b[34m(structure, flat, index)\u001b[39m\n\u001b[32m    605\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m _tf_data_is_nested(s):\n\u001b[32m    606\u001b[39m   new_index, child = _tf_data_packed_nest_with_indices(s, flat, index)\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m   packed.append(\u001b[43msequence_like\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchild\u001b[49m\u001b[43m)\u001b[49m)  \u001b[38;5;66;03m# pylint: disable=protected-access\u001b[39;00m\n\u001b[32m    608\u001b[39m   index = new_index\n\u001b[32m    609\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/anaconda3/envs/tensorflow/lib/python3.11/site-packages/tensorflow/python/util/nest_util.py:249\u001b[39m, in \u001b[36msequence_like\u001b[39m\u001b[34m(instance, args)\u001b[39m\n\u001b[32m    246\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m instance.__tf_unflatten__(metadata, \u001b[38;5;28mtuple\u001b[39m(args))\n\u001b[32m    247\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    248\u001b[39m   \u001b[38;5;66;03m# Not a namedtuple\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43minstance\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: Column.__init__() missing 1 required positional argument: 'column_name'"
     ]
    }
   ],
   "source": [
    "train_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (ds[\"train\"][\"pixel_values\"], ds[\"train\"][\"labels\"])\n",
    ").batch(32)\n",
    "\n",
    "test_set = tf.data.Dataset.from_tensor_slices(\n",
    "    (ds[\"test\"][\"pixel_values\"], ds[\"test\"][\"labels\"])\n",
    ").batch(32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cf74f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
